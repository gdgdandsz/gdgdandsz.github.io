---
title: Personalizing Large Language Models for Value Judgments Based on Cognitive Models
date: 2024-07-25
tags:
  - LLM
  - Prompt Engineering
  - Fine-tuning
---
Capstone, Supervised by Prof. Hongyi Wen, NYUSH.<br>
Conducted an in-depth study on aligning large language models (LLMs) with human cognitive processes to generate more personalized value-based judgments.<br>
Designed personalized responses through prompt engineering and K-Means clustering, tailoring outputs to unique respondent profiles.<br>
Fine-tuned LLaMA 3.1 using Low-Rank Adaptation (LoRA) to create cluster-specific models, enhancing cognitive alignment and model adaptability.<br>
Addressed challenges in adapting models for diverse question types (e.g., multiple-choice and sorting questions) through custom input and output modifications.<br>
Evaluated model performance through simulations, verifying its ability to generalize across various value-based topics within social science domains.<br>



<!--more-->
