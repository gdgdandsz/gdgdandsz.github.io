---
title: Personalizing Large Language Models for Value Judgments Based on Cognitive Models
date: 2024-07-25
tags:
  - LLM
  - Prompt Engineering
  - Fine-tuning
---
Capstone, Supervised by Prof. Hongyi Wen, NYUSH.
Conducted an in-depth study on aligning large language models (LLMs) with human cognitive processes to generate more personalized value-based judgments.
Designed personalized responses through prompt engineering and K-Means clustering, tailoring outputs to unique respondent profiles.
Fine-tuned LLaMA 3.1 using Low-Rank Adaptation (LoRA) to create cluster-specific models, enhancing cognitive alignment and model adaptability.
Addressed challenges in adapting models for diverse question types (e.g., multiple-choice and sorting questions) through custom input and output modifications.
Evaluated model performance through simulations, verifying its ability to generalize across various value-based topics within social science domains.



<!--more-->
